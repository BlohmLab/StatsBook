
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>8. Bayesian statistics and hypothesis testing &#8212; NSCI 801 - Quantitative Neuroscience book</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="9. Models in Neuroscience" href="NSCI801_ModelFitting.html" />
    <link rel="prev" title="7. Image Processing" href="NSCI801_Image_Processing_Proper_v2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">NSCI 801 - Quantitative Neuroscience book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="README.html">
   NSCI 801 - Quantitative Neuroscience Syllabus
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_Intro.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_intro_python.html">
   2. Google COLAB and Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_advanced_python.html">
   3. Advanced Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_acquisition_filters.html">
   4. Data Collection and Signal Processing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_Descriptive_Stats-NEW.html">
   5. Descriptive Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_Advanced_stats.html">
   6. Advanced Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_Image_Processing_Proper_v2.html">
   7. Image Processing
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   8. Bayesian statistics and hypothesis testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_ModelFitting.html">
   9. Models in Neuroscience
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_DataNeuroscience.html">
   10. Data Neuroscience Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_CorrelationVsCausality.html">
   11. Correlation vs. Causality
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NSCI801_Reproducibility.html">
   12. Reproducibility, reliability, validity
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/NSCI801_Bayesian-stats.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FNSCI801_Bayesian-stats.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/NSCI801_Bayesian-stats.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nsci-801-quantitative-neuroscience">
   8.1. NSCI 801 - Quantitative Neuroscience
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#motivation-and-pitfalls-of-classic-methods">
     8.1.1. Motivation and pitfalls of classic methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     8.1.2. Motivation and pitfalls of classic methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conditional-probabilities-and-bayes-rule">
     8.1.3. Conditional probabilities and Bayes rule
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayes-rule-example">
     8.1.4. Bayes rule example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-integration-with-uncertainty">
     8.1.5. Bayesian integration with uncertainty
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayes-factor">
     8.1.6. Bayes Factor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     8.1.7. Bayes Factor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayes-factor-simple-example">
     8.1.8. Bayes factor: simple example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     8.1.9. Bayes Factor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     8.1.10. Bayes Factor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayes-factor-other-bayesian-stats">
     8.1.11. Bayes Factor (&amp; other Bayesian stats)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hypothesis-testing-with-bayesian-estimation-gg-t-test">
     8.1.12. Hypothesis testing with Bayesian estimation
     <span class="math notranslate nohighlight">
      \(\gg\)
     </span>
     t-test
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#drug-trial-evaluation">
       8.1.12.1. Drug trial evaluation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-estimation-step-1-specify-full-probability-model">
     8.1.13. Bayesian estimation step 1: specify full probability model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-estimation-step-2-specify-priors">
     8.1.14. Bayesian estimation step 2: specify priors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-estimation-step-3-compute-comparison-of-interest">
     8.1.15. Bayesian estimation step 3: compute comparison of interest
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-estimation-step-4-fit-model-and-evaluate-output">
     8.1.16. Bayesian estimation step 4: fit model and evaluate output
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-estimation-step-5-estimate-quantity-of-interest">
     8.1.17. Bayesian estimation step 5: estimate quantity of interest
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-anova">
     8.1.18. Bayesian ANOVA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     8.1.19. Bayesian ANOVA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-readings">
     8.1.20. Further readings
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Bayesian statistics and hypothesis testing</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nsci-801-quantitative-neuroscience">
   8.1. NSCI 801 - Quantitative Neuroscience
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#motivation-and-pitfalls-of-classic-methods">
     8.1.1. Motivation and pitfalls of classic methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     8.1.2. Motivation and pitfalls of classic methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conditional-probabilities-and-bayes-rule">
     8.1.3. Conditional probabilities and Bayes rule
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayes-rule-example">
     8.1.4. Bayes rule example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-integration-with-uncertainty">
     8.1.5. Bayesian integration with uncertainty
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayes-factor">
     8.1.6. Bayes Factor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     8.1.7. Bayes Factor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayes-factor-simple-example">
     8.1.8. Bayes factor: simple example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     8.1.9. Bayes Factor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     8.1.10. Bayes Factor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayes-factor-other-bayesian-stats">
     8.1.11. Bayes Factor (&amp; other Bayesian stats)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hypothesis-testing-with-bayesian-estimation-gg-t-test">
     8.1.12. Hypothesis testing with Bayesian estimation
     <span class="math notranslate nohighlight">
      \(\gg\)
     </span>
     t-test
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#drug-trial-evaluation">
       8.1.12.1. Drug trial evaluation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-estimation-step-1-specify-full-probability-model">
     8.1.13. Bayesian estimation step 1: specify full probability model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-estimation-step-2-specify-priors">
     8.1.14. Bayesian estimation step 2: specify priors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-estimation-step-3-compute-comparison-of-interest">
     8.1.15. Bayesian estimation step 3: compute comparison of interest
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-estimation-step-4-fit-model-and-evaluate-output">
     8.1.16. Bayesian estimation step 4: fit model and evaluate output
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-estimation-step-5-estimate-quantity-of-interest">
     8.1.17. Bayesian estimation step 5: estimate quantity of interest
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-anova">
     8.1.18. Bayesian ANOVA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     8.1.19. Bayesian ANOVA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#further-readings">
     8.1.20. Further readings
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="bayesian-statistics-and-hypothesis-testing">
<h1><span class="section-number">8. </span>Bayesian statistics and hypothesis testing<a class="headerlink" href="#bayesian-statistics-and-hypothesis-testing" title="Permalink to this headline">¶</a></h1>
<div class="section" id="nsci-801-quantitative-neuroscience">
<h2><span class="section-number">8.1. </span>NSCI 801 - Quantitative Neuroscience<a class="headerlink" href="#nsci-801-quantitative-neuroscience" title="Permalink to this headline">¶</a></h2>
<p>Gunnar Blohm</p>
<div class="section" id="motivation-and-pitfalls-of-classic-methods">
<h3><span class="section-number">8.1.1. </span>Motivation and pitfalls of classic methods<a class="headerlink" href="#motivation-and-pitfalls-of-classic-methods" title="Permalink to this headline">¶</a></h3>
<p>Frequentist statistics assumptions:</p>
<ul class="simple">
<li><p>parameters are unknown but <strong>fixed</strong></p></li>
<li><p>uncertainty is in the <strong>sample</strong> based on the idea of infinite repeated sampling</p></li>
<li><p><strong>ignores</strong> prior knowledge</p></li>
</ul>
<p>Bayesian alternative assumptions:</p>
<ul class="simple">
<li><p>parameters are unknown and therefore <strong>random</strong></p></li>
<li><p>uncertainty is the probability <strong>distribution of the population parameter</strong></p></li>
<li><p>explicitly <strong>includes</strong> prior knowledge</p></li>
</ul>
<p>Pragmatically, sometimes it makes sense to use frequentist approach, sometimes it makes sense to use Bayesian approach, sometimes it’s best to provide both!</p>
<p><img alt="bias" src="_images/FB5w13tVcAQrxOm.jpg" /></p>
</div>
<div class="section" id="id1">
<h3><span class="section-number">8.1.2. </span>Motivation and pitfalls of classic methods<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>So what do Bayesian stats buy you?</p>
<ul class="simple">
<li><p>incorporates background knowledge (frequentists stats test the same Null Hyp. over and over again)</p></li>
<li><p>you expect something is going on if you did this experiment / analysis <span class="math notranslate nohighlight">\(\rightarrow\)</span> Null Hyp. (= “nothing is going on”) is often a bad starting point</p></li>
<li><p>allows to explicitly carry out replication analyses (due to integration of background) <span class="math notranslate nohighlight">\(\rightarrow\)</span> plausibility of previous research findings can be evaluated in the light of new data</p></li>
<li><p>gives you the probability of the (Null) Hyp.</p></li>
<li><p>statistical evaluations are based on <em>estimation</em> rather than <em>testing</em>: i.e. rather than testing whether two groups are different, we instead pursue an estimate of how different they are, which is fundamentally more informative</p></li>
<li><p>includes an estimate of uncertainty associated with the estimated quantity</p></li>
</ul>
<p><img alt="base rate" src="_images/base_rate.png" /></p>
</div>
<div class="section" id="conditional-probabilities-and-bayes-rule">
<h3><span class="section-number">8.1.3. </span>Conditional probabilities and Bayes rule<a class="headerlink" href="#conditional-probabilities-and-bayes-rule" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[ P(a,b) = P(a|b) P(b) = P(b|a) P(a)\]</div>
<p>Rearranging, results in:
$<span class="math notranslate nohighlight">\( P(a|b) = \frac{P(b|a)P(a)}{P(b)}\)</span><span class="math notranslate nohighlight">\(
With:
\)</span><span class="math notranslate nohighlight">\( P(b) = \sum_{j} P(b|a_j)P(a_j) \)</span>$</p>
</div>
<div class="section" id="bayes-rule-example">
<h3><span class="section-number">8.1.4. </span>Bayes rule example<a class="headerlink" href="#bayes-rule-example" title="Permalink to this headline">¶</a></h3>
<p><img alt="Bayes rule" src="_images/Cancer_cond_prob.png" /></p>
<div class="math notranslate nohighlight">
\[P(cancer | test+) = \frac{P(test+ | cancer) P(cancer)}{P(test+)}\]</div>
<div class="math notranslate nohighlight">
\[P(cancer | test+) = \frac{9/10 * 10/1000}{9/10 * 10/1000 + 99/990 * 990/1000} = 9/108 = 8.3 \% \]</div>
</div>
<div class="section" id="bayesian-integration-with-uncertainty">
<h3><span class="section-number">8.1.5. </span>Bayesian integration with uncertainty<a class="headerlink" href="#bayesian-integration-with-uncertainty" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[ P(a|b) = \frac{P(b|a)P(a)}{P(b)}\]</div>
<p><img alt="Bayes distribution" src="_images/Bayes-distributions.png" /></p>
</div>
<div class="section" id="bayes-factor">
<h3><span class="section-number">8.1.6. </span>Bayes Factor<a class="headerlink" href="#bayes-factor" title="Permalink to this headline">¶</a></h3>
<p><strong>A general method for hypothesis testing!</strong></p>
<p>Let’s start with data (<span class="math notranslate nohighlight">\(\mathbf{D}\)</span>), assumed to have arisen under one of two hypotheses <span class="math notranslate nohighlight">\(H_1\)</span> or <span class="math notranslate nohighlight">\(H_2\)</span>, according to <span class="math notranslate nohighlight">\(P(\mathbf{D}|H_1)\)</span> and <span class="math notranslate nohighlight">\(P(\mathbf{D}|H_2)\)</span>. Then we can compute the posterior:</p>
<div class="math notranslate nohighlight">
\[P(H_k|\mathbf{D}) = \frac{P(\mathbf{D}|H_k) P(H_k)}{P(\mathbf{D}|H_1) P(H_1) + P(\mathbf{D}|H_2) P(H_2)}\]</div>
<p>What we really want to know is the odds that the data is more consistent with <span class="math notranslate nohighlight">\(H_1\)</span> than with <span class="math notranslate nohighlight">\(H_2\)</span>. (reminder: odds = probability / (1-probability)). We thus want to know:</p>
<div class="math notranslate nohighlight">
\[\frac{P(H_1|\mathbf{D})}{P(H_2|\mathbf{D})} = \frac{P(\mathbf{D}|H_1)}{P(\mathbf{D}|H_2)} \frac{P(H_1)}{P(H_2)} = B_{21} \frac{P(H_1)}{P(H_2)}\]</div>
<p>where <span class="math notranslate nohighlight">\(B_{12}\)</span> is the Bayes Factor, i.e. the ratio of posterior odds <strong>regardless</strong> of the value of  the prior odds!</p>
</div>
<div class="section" id="id2">
<h3><span class="section-number">8.1.7. </span>Bayes Factor<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p><strong>A general method for hypothesis testing!</strong></p>
<p>Bayes Factor (BF) is a quantity for the evidence in observed data to support one model (or hypothesis) against another, where the two models are usually a “null” (<span class="math notranslate nohighlight">\(H_1\)</span>) vs an “alternative” (<span class="math notranslate nohighlight">\(H_2\)</span>).</p>
<p>Sometimes a <strong>Bayesian p-value</strong> is computed as:
$<span class="math notranslate nohighlight">\(\frac{P(\mathbf{D}|H_2)}{P(\mathbf{D}|H_1) + P(\mathbf{D}|H_2)}\)</span><span class="math notranslate nohighlight">\(
(or vice versa if interested in \)</span>H_2$)</p>
<p><strong>Note</strong>: you can use this not just for hypothesis testing, but for comparison of <strong>any</strong> 2 models!!!</p>
</div>
<div class="section" id="bayes-factor-simple-example">
<h3><span class="section-number">8.1.8. </span>Bayes factor: simple example<a class="headerlink" href="#bayes-factor-simple-example" title="Permalink to this headline">¶</a></h3>
<p>Coin flipping example. Suppose you flip a coin 100 times. Joe believes the coin is uneven and that heads have a 75% probability. Gunnar believes it’s even. After 100 tosses, the coin lands 62 heads. Is it an uneven coin?</p>
<p><span class="math notranslate nohighlight">\(H_1\)</span>: even coin: <span class="math notranslate nohighlight">\(P(heads)=0.5\)</span></p>
<p><span class="math notranslate nohighlight">\(H_2\)</span>: uneven coin with <span class="math notranslate nohighlight">\(P(heads)=0.75\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;dark_background&#39;</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># number coin flips</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">dist1</span> <span class="o">=</span> <span class="n">binom</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span> <span class="c1"># Gunnar&#39;s belief</span>
<span class="n">dist2</span> <span class="o">=</span> <span class="n">binom</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">)</span> <span class="c1"># Joe&#39;s belief</span>
<span class="n">toss</span> <span class="o">=</span> <span class="mi">62</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dist1</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dist2</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">toss</span><span class="p">,</span> <span class="n">toss</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="nn">Input In [1],</span> in <span class="ni">&lt;cell line: 1&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;numpy&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute Bayes Factor</span>
<span class="n">toss</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">gunnar</span> <span class="o">=</span> <span class="n">dist1</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">toss</span><span class="p">)</span> 
<span class="n">joe</span> <span class="o">=</span> <span class="n">dist2</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">toss</span><span class="p">)</span> <span class="c1">#pmf: probability mass function (to get probability of observing toss given a distribution)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;BF = &quot;</span><span class="p">,</span> <span class="n">joe</span><span class="o">/</span><span class="n">gunnar</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Bayesian p-value = &quot;</span><span class="p">,</span> <span class="n">gunnar</span><span class="o">/</span><span class="p">(</span><span class="n">joe</span><span class="o">+</span><span class="n">gunnar</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BF =  6.683928594286566e-19
Bayesian p-value =  1.0
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id3">
<h3><span class="section-number">8.1.9. </span>Bayes Factor<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p><strong>Interpretation</strong></p>
<p><img alt="BF" src="_images/BF-interpr.png" /></p>
</div>
<div class="section" id="id4">
<h3><span class="section-number">8.1.10. </span>Bayes Factor<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>Unfortunately, in real life things are usually more complicated…</p>
<p>e.g. <span class="math notranslate nohighlight">\(H_1\)</span>: even coin; <span class="math notranslate nohighlight">\(H_2\)</span>: uneven coin (any probability)</p>
<p>Now we have to compute the following:
$<span class="math notranslate nohighlight">\(B = \frac{\int_{\Theta_1} P(X| \theta) P(\theta | H_1) d \theta}{\int_{\Theta_2} P(X| \theta) P(\theta | H_2) d \theta}\)</span>$</p>
</div>
<div class="section" id="bayes-factor-other-bayesian-stats">
<h3><span class="section-number">8.1.11. </span>Bayes Factor (&amp; other Bayesian stats)<a class="headerlink" href="#bayes-factor-other-bayesian-stats" title="Permalink to this headline">¶</a></h3>
<p>Practically, there are easier ways to do this than in Python…</p>
<ul class="simple">
<li><p><a class="reference external" href="https://jasp-stats.org/">JASP</a></p></li>
<li><p><a class="reference external" href="https://cran.r-project.org/web/views/Bayesian.html">Bayesian Inference in R</a></p></li>
</ul>
<p>If you want to use Python (totally possible)</p>
<ul class="simple">
<li><p>call R packages from Python with <a class="reference external" href="https://rpy2.readthedocs.io/en/latest/">rpy2</a></p></li>
<li><p>use <a class="reference external" href="https://docs.pymc.io/">PyMC3</a></p></li>
<li><p>use <a class="reference external" href="https://mc-stan.org/users/interfaces/pystan">PyStan</a></p></li>
</ul>
</div>
<div class="section" id="hypothesis-testing-with-bayesian-estimation-gg-t-test">
<h3><span class="section-number">8.1.12. </span>Hypothesis testing with Bayesian estimation <span class="math notranslate nohighlight">\(\gg\)</span> t-test<a class="headerlink" href="#hypothesis-testing-with-bayesian-estimation-gg-t-test" title="Permalink to this headline">¶</a></h3>
<p><strong>Estimate</strong> how different 2 samples are…</p>
<div class="section" id="drug-trial-evaluation">
<h4><span class="section-number">8.1.12.1. </span>Drug trial evaluation<a class="headerlink" href="#drug-trial-evaluation" title="Permalink to this headline">¶</a></h4>
<p>fictitious example from <a class="reference external" href="https://pdfs.semanticscholar.org/dea6/0927efbd1f284b4132eae3461ea7ce0fb62a.pdf?_ga=2.26768573.1215645062.1614710292-1447250400.1614710292">Kruschke (2012)</a>: evaluation of a clinical trial for a “smart” drug that is supposed to increase intelligence</p>
<p>Goal: comparing IQ scores of individuals in a treatment arm (those receiving the drug; <span class="math notranslate nohighlight">\(N=47\)</span>) to those in a control arm (those recieving a placebo; <span class="math notranslate nohighlight">\(N=42\)</span>)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span> <span class="c1"># ArviZ: Exploratory analysis of Bayesian models</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> <span class="c1"># data analysis and manipulation tool</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span> <span class="c1"># Probabilistic Programming in Python</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span> <span class="c1"># for nice plotting</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># artificial data</span>
<span class="n">drug</span> <span class="o">=</span> <span class="p">(</span><span class="mi">101</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">104</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">97</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">98</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">123</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">103</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">95</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">106</span><span class="p">,</span>
        <span class="mi">109</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">82</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">103</span><span class="p">,</span><span class="mi">103</span><span class="p">,</span><span class="mi">97</span><span class="p">,</span><span class="mi">97</span><span class="p">,</span><span class="mi">103</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">97</span><span class="p">,</span><span class="mi">104</span><span class="p">,</span>
        <span class="mi">96</span><span class="p">,</span><span class="mi">103</span><span class="p">,</span><span class="mi">124</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">104</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">101</span><span class="p">)</span>
<span class="n">placebo</span> <span class="o">=</span> <span class="p">(</span><span class="mi">99</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">97</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">104</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">88</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span>
           <span class="mi">104</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">103</span><span class="p">,</span><span class="mi">97</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">99</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span>
           <span class="mi">101</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">99</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">102</span><span class="p">,</span><span class="mi">99</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">99</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">drug</span><span class="p">)</span>
<span class="n">y2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">placebo</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="nb">dict</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">y1</span><span class="p">,</span> <span class="n">y2</span><span class="p">],</span> <span class="n">group</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[[</span><span class="s2">&quot;drug&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">drug</span><span class="p">),</span> <span class="p">[</span><span class="s2">&quot;placebo&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">placebo</span><span class="p">)])</span>
<span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;group&quot;</span><span class="p">,</span> <span class="n">element</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.FacetGrid at 0x1d3edf18fa0&gt;
</pre></div>
</div>
<img alt="_images/NSCI801_Bayesian-stats_23_1.png" src="_images/NSCI801_Bayesian-stats_23_1.png" />
</div>
</div>
</div>
</div>
<div class="section" id="bayesian-estimation-step-1-specify-full-probability-model">
<h3><span class="section-number">8.1.13. </span>Bayesian estimation step 1: specify full probability model<a class="headerlink" href="#bayesian-estimation-step-1-specify-full-probability-model" title="Permalink to this headline">¶</a></h3>
<p>Here, Kruschke choses a Student t-distribution with 3 parameters to account for potential long tails in the distribution (compared to a Gaussian)…</p>
<ul class="simple">
<li><p>mean <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
<li><p>precision (inverse-variance) <span class="math notranslate nohighlight">\(\lambda\)</span></p></li>
<li><p>degrees-of-freedom parameter <span class="math notranslate nohighlight">\(\nu\)</span>: specifies “normality” of data</p></li>
</ul>
<p>Thus, the likelihood function of each model is (for drug and placebo) is specified by a Student t-distribution.</p>
<p>To simplify, let’s assume that the degree of normality <span class="math notranslate nohighlight">\(\nu\)</span> is the same for both groups.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot Student t-distribution with mean=0, SD=1 and different df</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">t</span>
<span class="n">df</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">df</span><span class="p">),</span>
                <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">df</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">.5</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;df=0.5&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;y-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;df=2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="s1">&#39;g-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;df=200&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x1d3f7b18070&gt;
</pre></div>
</div>
<img alt="_images/NSCI801_Bayesian-stats_25_1.png" src="_images/NSCI801_Bayesian-stats_25_1.png" />
</div>
</div>
</div>
<div class="section" id="bayesian-estimation-step-2-specify-priors">
<h3><span class="section-number">8.1.14. </span>Bayesian estimation step 2: specify priors<a class="headerlink" href="#bayesian-estimation-step-2-specify-priors" title="Permalink to this headline">¶</a></h3>
<p>We now need to specify a prior for each one of our model parameters <span class="math notranslate nohighlight">\(\mu\)</span>, <span class="math notranslate nohighlight">\(\sigma\)</span>, and <span class="math notranslate nohighlight">\(\nu\)</span>.</p>
<p>Since the means are real-valued, let’s apply a normally distributed prior. Let’s arbitrarily set the hyperparameters for the prior over the mean to the following:</p>
<ul class="simple">
<li><p>pooled empiral mean</p></li>
<li><p>twice the pooled empirical standard deviation (very diffuse)</p></li>
</ul>
<p>Importantly, this prior will <strong>NOT</strong> favour one over the other <em>a priori</em>. So let’s start creating our statistical model…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># prior over the mean</span>
<span class="n">mu_m</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">mu_s</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="mi">2</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">group1_mean</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;group1_mean&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu_m</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">mu_s</span><span class="p">)</span>
    <span class="n">group2_mean</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;group2_mean&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu_m</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">mu_s</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s give the group standard deviations a uniform prior over a plausible range of values for the variability of the outcome variable</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># prior over the SD</span>
<span class="n">sig_low</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">sig_high</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">group1_std</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">&quot;group1_std&quot;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="n">sig_low</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">sig_high</span><span class="p">)</span>
    <span class="n">group2_std</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">&quot;group2_std&quot;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="n">sig_low</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="n">sig_high</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we need a prior over <span class="math notranslate nohighlight">\(\nu\)</span> (degree of freedom).</p>
<p>Since <span class="math notranslate nohighlight">\(\nu&gt;0\)</span>, we will chose an exponential distribution with a mean of 30 (this allocates high prior probability over the regions of the parameter that describe the range from normal to heavy-tailed data under the Student-T distribution.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s2">&quot;nu_minus_one&quot;</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="mf">29.0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    
<span class="n">pm</span><span class="o">.</span><span class="n">plot_kde</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span> <span class="n">fill_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">},</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;expon sample&#39;</span><span class="p">);</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">expon</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span>
                <span class="n">expon</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.999</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">30</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">expon</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">30</span><span class="p">,</span>
       <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;expon pdf&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x1d3f84147f0&gt;
</pre></div>
</div>
<img alt="_images/NSCI801_Bayesian-stats_31_1.png" src="_images/NSCI801_Bayesian-stats_31_1.png" />
</div>
</div>
<p>PyMC3 parameterizes the Student-T in terms of precision, rather than standard deviation; therefore the prior over <span class="math notranslate nohighlight">\(\nu\)</span> writes as follows</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">lamda1</span> <span class="o">=</span> <span class="n">group1_std</span> <span class="o">**</span> <span class="o">-</span><span class="mi">2</span>
    <span class="n">lamda2</span> <span class="o">=</span> <span class="n">group2_std</span> <span class="o">**</span> <span class="o">-</span><span class="mi">2</span>

    <span class="n">group1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s2">&quot;drug&quot;</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">nu</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">group1_mean</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="n">lamda1</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y1</span><span class="p">)</span>
    <span class="n">group2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s2">&quot;placebo&quot;</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">nu</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">group2_mean</span><span class="p">,</span> <span class="n">lam</span><span class="o">=</span><span class="n">lamda2</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bayesian-estimation-step-3-compute-comparison-of-interest">
<h3><span class="section-number">8.1.15. </span>Bayesian estimation step 3: compute comparison of interest<a class="headerlink" href="#bayesian-estimation-step-3-compute-comparison-of-interest" title="Permalink to this headline">¶</a></h3>
<p>What is the effect of the drug?</p>
<ul class="simple">
<li><p>determine difference between group means</p></li>
<li><p>determine difference between group SDs</p></li>
<li><p>determine effect size, i.e. difference in means scaled by the pooled estimates of standard deviation</p></li>
</ul>
<p>Wrapping them in named “Deterministic” objects signals to PyMC that we wish to record the sampled values as part of the output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">diff_of_means</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">&quot;difference of means&quot;</span><span class="p">,</span> <span class="n">group1_mean</span> <span class="o">-</span> <span class="n">group2_mean</span><span class="p">)</span>
    <span class="n">diff_of_stds</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">&quot;difference of stds&quot;</span><span class="p">,</span> <span class="n">group1_std</span> <span class="o">-</span> <span class="n">group2_std</span><span class="p">)</span>
    <span class="n">effect_size</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">&quot;effect size&quot;</span><span class="p">,</span> <span class="n">diff_of_means</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">group1_std</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">group2_std</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bayesian-estimation-step-4-fit-model-and-evaluate-output">
<h3><span class="section-number">8.1.16. </span>Bayesian estimation step 4: fit model and evaluate output<a class="headerlink" href="#bayesian-estimation-step-4-fit-model-and-evaluate-output" title="Permalink to this headline">¶</a></h3>
<p>This is now super simple thanks to Python magic…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Gunnar\AppData\Local\Temp/ipykernel_22956/3903337930.py:2: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.
  trace = pm.sample(2000)
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [nu_minus_one, group2_std, group1_std, group2_mean, group1_mean]
</pre></div>
</div>
<div class="output text_html">
<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div><div class="output text_html">
<div>
  <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>
  100.00% [12000/12000 00:05<00:00 Sampling 4 chains, 0 divergences]
</div>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 22 seconds.
</pre></div>
</div>
</div>
</div>
<p>Some explanations…</p>
<ul class="simple">
<li><p>NUTS is a Markov-Chain Monte-Carlo (MCMC) sampler: No-U-Turn Sampler</p></li>
<li><p>MCMC sampler: a way to sample from a given distribution by building a Markov chain that has the desired distribution as its equilibrium distribution</p></li>
</ul>
<p>Ok, back to our model: we can now plot the fit results. We will plot:</p>
<ul class="simple">
<li><p>the posterior distributions of the parameters</p></li>
<li><p>the 95% credible interval, or highest (posterior) density interval (HDI)</p></li>
<li><p>the posterior mean</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span>
    <span class="n">trace</span><span class="p">,</span>
    <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;group1_mean&quot;</span><span class="p">,</span> <span class="s2">&quot;group2_mean&quot;</span><span class="p">,</span> <span class="s2">&quot;group1_std&quot;</span><span class="p">,</span> <span class="s2">&quot;group2_std&quot;</span><span class="p">,</span> <span class="s2">&quot;nu_minus_one&quot;</span><span class="p">],</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#87ceeb&quot;</span><span class="p">,);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\ProgramData\Anaconda3\lib\site-packages\arviz\data\io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.
  warnings.warn(
</pre></div>
</div>
<img alt="_images/NSCI801_Bayesian-stats_40_1.png" src="_images/NSCI801_Bayesian-stats_40_1.png" />
</div>
</div>
</div>
<div class="section" id="bayesian-estimation-step-5-estimate-quantity-of-interest">
<h3><span class="section-number">8.1.17. </span>Bayesian estimation step 5: estimate quantity of interest<a class="headerlink" href="#bayesian-estimation-step-5-estimate-quantity-of-interest" title="Permalink to this headline">¶</a></h3>
<p>Is there a difference between drug vs placebo samples?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span>
    <span class="n">trace</span><span class="p">,</span>
    <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;difference of means&quot;</span><span class="p">,</span> <span class="s2">&quot;difference of stds&quot;</span><span class="p">,</span> <span class="s2">&quot;effect size&quot;</span><span class="p">],</span>
    <span class="n">ref_val</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#87ceeb&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\ProgramData\Anaconda3\lib\site-packages\arviz\data\io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.
  warnings.warn(
</pre></div>
</div>
<img alt="_images/NSCI801_Bayesian-stats_42_1.png" src="_images/NSCI801_Bayesian-stats_42_1.png" />
</div>
</div>
<p><strong>Results</strong>:</p>
<ul class="simple">
<li><p>“smart drug” increases mean IQ</p></li>
<li><p>“smart drug” increases variability in IQ scores</p></li>
<li><p>“smart drug” has a non-zero effect size</p></li>
</ul>
<p>Note: this does NOT mean all participants would benefit from the drug! Some might be adversely affected…</p>
<p><strong>Further analysis</strong>:</p>
<p>let’s look at some more details, i.e.</p>
<ul class="simple">
<li><p>group parameter differences</p></li>
<li><p>group summary table</p></li>
</ul>
<p>(MCSE: Markov chain standard error; [ESS: effective sample size estimate](<a class="reference external" href="https://www.displayr.com/what-is-effective-sample-size/#:~:text=The%20effective%20sample%20size%20(ESS,amount%20of%20information%20in%20data.)">https://www.displayr.com/what-is-effective-sample-size/#:~:text=The effective sample size (ESS,amount of information in data.)</a>; R-hat diagnostic tests for lack of convergence - 1 means it converged)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;group1_mean&quot;</span><span class="p">,</span> <span class="s2">&quot;group2_mean&quot;</span><span class="p">]);</span> <span class="c1"># we ran 4 chains, we&#39;ll thus get 4 HDI estimates</span>
<span class="n">pm</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;group1_std&quot;</span><span class="p">,</span> <span class="s2">&quot;group2_std&quot;</span><span class="p">,</span> <span class="s2">&quot;nu_minus_one&quot;</span><span class="p">]);</span>
<span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s2">&quot;stats&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\ProgramData\Anaconda3\lib\site-packages\arviz\data\io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.
  warnings.warn(
C:\ProgramData\Anaconda3\lib\site-packages\arviz\data\io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.
  warnings.warn(
C:\ProgramData\Anaconda3\lib\site-packages\arviz\data\io_pymc3.py:96: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.
  warnings.warn(
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>group1_mean</th>
      <td>101.551</td>
      <td>0.387</td>
      <td>100.832</td>
      <td>102.283</td>
    </tr>
    <tr>
      <th>group2_mean</th>
      <td>100.535</td>
      <td>0.223</td>
      <td>100.121</td>
      <td>100.953</td>
    </tr>
    <tr>
      <th>group1_std</th>
      <td>2.122</td>
      <td>0.438</td>
      <td>1.372</td>
      <td>2.989</td>
    </tr>
    <tr>
      <th>group2_std</th>
      <td>1.194</td>
      <td>0.158</td>
      <td>1.000</td>
      <td>1.474</td>
    </tr>
    <tr>
      <th>nu_minus_one</th>
      <td>0.979</td>
      <td>0.507</td>
      <td>0.130</td>
      <td>1.932</td>
    </tr>
    <tr>
      <th>difference of means</th>
      <td>1.016</td>
      <td>0.448</td>
      <td>0.135</td>
      <td>1.816</td>
    </tr>
    <tr>
      <th>difference of stds</th>
      <td>0.928</td>
      <td>0.449</td>
      <td>0.126</td>
      <td>1.794</td>
    </tr>
    <tr>
      <th>effect size</th>
      <td>0.605</td>
      <td>0.282</td>
      <td>0.072</td>
      <td>1.126</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="_images/NSCI801_Bayesian-stats_45_2.png" src="_images/NSCI801_Bayesian-stats_45_2.png" />
<img alt="_images/NSCI801_Bayesian-stats_45_3.png" src="_images/NSCI801_Bayesian-stats_45_3.png" />
</div>
</div>
</div>
<div class="section" id="bayesian-anova">
<h3><span class="section-number">8.1.18. </span>Bayesian ANOVA<a class="headerlink" href="#bayesian-anova" title="Permalink to this headline">¶</a></h3>
<p>The idea is again that we use ANOVA for model (hypothesis) comparison.</p>
<p>Supposed you have 2 fixed factors A and B. Then a Bayesian ANOVA will test the following models:</p>
<ul class="simple">
<li><p>the null model</p></li>
<li><p>the model with a main effect of A</p></li>
<li><p>the model with a main effect of B</p></li>
<li><p>the model with a main effect of A and a main effect of B</p></li>
<li><p>the model with a main effect of A, a main effect of B, and an interaction between A and B</p></li>
</ul>
</div>
<div class="section" id="id5">
<h3><span class="section-number">8.1.19. </span>Bayesian ANOVA<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>Bayesian ANOVAs will compute the Bayes Factor and use the priors to estimate the posterior model probabilities.</p>
<p>ANOVA-based Bayes Factors typically use the best model as a reference</p>
<p>This is easy to do / interpret with <a class="reference external" href="https://jasp-stats.org/">JASP</a></p>
</div>
<div class="section" id="further-readings">
<h3><span class="section-number">8.1.20. </span>Further readings<a class="headerlink" href="#further-readings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.nature.com/articles/s41593-020-0660-4">Using Bayes factor hypothesis testing in neuroscience to establish evidence of absence</a></p></li>
<li><p><a class="reference external" href="http://www.stat.columbia.edu/~gelman/book/">Bayesian data analysis</a></p></li>
<li><p><a class="reference external" href="https://www.nature.com/articles/s43586-020-00001-2">Bayesian statistics and modelling</a></p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="NSCI801_Image_Processing_Proper_v2.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">7. </span>Image Processing</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="NSCI801_ModelFitting.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">9. </span>Models in Neuroscience</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Gunnar Blohm, Joe Nashed<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>